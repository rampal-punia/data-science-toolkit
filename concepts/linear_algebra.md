## Linear Algebra & Calculus

Here is a list of 51 important keywords related to linear algebra and calculus, along with their brief definitions:

### Linear Algebra

1. **Vector**: An ordered list of numbers that represent a point in space, often used to describe magnitude and direction.

2. **Matrix**: A rectangular array of numbers or functions arranged in rows and columns, used in linear transformations and systems of linear equations.

3. **Scalar**: A single number, often used to scale or multiply vectors and matrices.

4. **Dot Product**: A scalar product of two vectors, calculated as the sum of the products of their corresponding components.

5. **Cross Product**: A vector product of two vectors in three-dimensional space, resulting in a vector perpendicular to both.

6. **Norm**: A measure of the length or magnitude of a vector, often calculated using the Euclidean distance.

7. **Transpose**: The operation of flipping a matrix over its diagonal, turning rows into columns and vice versa.

8. **Inverse of a Matrix**: A matrix that, when multiplied by the original matrix, yields the identity matrix.

9. **Determinant**: A scalar value that can be computed from the elements of a square matrix, indicating whether the matrix is invertible and the volume scaling factor of the linear transformation.

10. **Rank**: The dimension of the vector space spanned by the rows or columns of a matrix, indicating the number of linearly independent rows or columns.

11. **Eigenvalue**: A scalar that indicates how much a corresponding eigenvector is stretched or shrunk during a linear transformation.

12. **Eigenvector**: A non-zero vector that changes at most by a scalar factor during a linear transformation associated with an eigenvalue.

13. **Singular Value Decomposition (SVD)**: A factorization of a matrix into three matrices, revealing the intrinsic geometric structure of the matrix.

14. **Diagonalization**: The process of converting a matrix into a diagonal matrix by a similarity transformation, using its eigenvalues and eigenvectors.

15. **Orthogonal Matrix**: A square matrix whose rows and columns are orthonormal vectors, preserving lengths and angles during transformations.

16. **Identity Matrix**: A square matrix with ones on the diagonal and zeros elsewhere, serving as the multiplicative identity in matrix operations.

17. **Symmetric Matrix**: A square matrix that is equal to its transpose, having mirror symmetry along the diagonal.

18. **Positive Definite Matrix**: A matrix where all its eigenvalues are positive, indicating that it defines a convex quadratic form.

19. **Trace of a Matrix**: The sum of the elements on the main diagonal of a square matrix, often used in matrix calculus.

20. **Linear Transformation**: A mapping between vector spaces that preserves vector addition and scalar multiplication.

21. **Column Space**: The set of all possible linear combinations of the column vectors of a matrix, also known as the range or image.

22. **Row Space**: The set of all possible linear combinations of the row vectors of a matrix.

23. **Null Space**: The set of all vectors that, when multiplied by a given matrix, yield the zero vector.

24. **LU Decomposition**: The factorization of a matrix into a lower triangular matrix (L) and an upper triangular matrix (U).

25. **Cholesky Decomposition**: A factorization of a positive-definite matrix into the product of a lower triangular matrix and its transpose.

26. **Gram-Schmidt Process**: An algorithm for orthogonalizing a set of vectors in an inner product space, producing an orthonormal set.
